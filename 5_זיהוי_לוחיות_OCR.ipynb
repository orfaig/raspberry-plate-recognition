{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6add1cab",
   "metadata": {},
   "source": [
    "## 📚 שלב 1: ייבוא ספריות והכנת כלים\n",
    "\n",
    "**חדש כאן:**\n",
    "- `onnxruntime` - להרצת מודל ה-AI (YOLO)\n",
    "- `pytesseract` - לקריאת טקסט מתמונות\n",
    "\n",
    "**קבצים שנצטרך:**\n",
    "- `yolov8n-license_plate.onnx` - מודל ה-AI המאומן\n",
    "- `/usr/bin/tesseract` - תוכנת ה-OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2380cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0;93m2026-01-19 00:08:44.793849064 [W:onnxruntime:Default, device_discovery.cc:164 DiscoverDevicesForPlatform] GPU device discovery failed: device_discovery.cc:89 ReadFileContents Failed to open file: \"/sys/class/drm/card1/device/vendor\"\u001b[m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Camera intrinsics K:\n",
      "[[450.   0. 320.]\n",
      " [  0. 600. 240.]\n",
      " [  0.   0.   1.]]\n",
      "[INFO] YOLO model input size: 512x512\n",
      "✅ ספריות נטענו!\n",
      "📍 Tesseract: /usr/bin/tesseract\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "import onnxruntime as onnxr\n",
    "import re\n",
    "\n",
    "from helper_function import (\n",
    "    run_onnx_inference,  # מריץ את ה-AI\n",
    "    decode_yolov8,       # מפענח את התוצאות\n",
    "    free_camera          # משחרר מצלמה תקועה\n",
    ")\n",
    "\n",
    "# הגדרות Tesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = \"/usr/bin/tesseract\"\n",
    "\n",
    "# הגדרות OCR - מה הוא יחפש\n",
    "CONFIG_TESS = (\n",
    "    \"--oem 1 --psm 7 \"  # מצב זיהוי\n",
    "    \"-c tessedit_char_whitelist=0123456789 \"  # רק ספרות!\n",
    "    \"-c classify_bln_numeric_mode=1 \"\n",
    "    \"-c user_defined_dpi=200 \"\n",
    ")\n",
    "\n",
    "print(\"✅ ספריות נטענו!\")\n",
    "print(f\"📍 Tesseract: {pytesseract.pytesseract.tesseract_cmd}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f253873",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 🤖 שלב 2: טעינת מודל ה-AI (YOLO)\n",
    "\n",
    "**מה זה YOLO?**  \n",
    "זה מודל AI שמאומן לזהות לוחיות רכב. הוא \"מסומן\" איפה הלוחית בתמונה.\n",
    "\n",
    "**פורמט ONNX:**  \n",
    "זה פורמט \"סטנדרטי\" למודלי AI שעובד טוב על Raspberry Pi.\n",
    "\n",
    "**פרמטרים:**\n",
    "- `CONF_THRES = 0.2` - סף ביטחון (20% = מקל, 80% = קפדני)\n",
    "- `IOU_THRES = 0.2` - למניעת זיהויים כפולים\n",
    "- `INFER_PERIOD_S = 0.03` - כמה פעמים בשנייה להריץ את ה-AI (כל 30ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9b79c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ מודל YOLO נטען!\n",
      "📊 קלט: images, צורה: [1, 3, 512, 512]\n",
      "⚙️ CONF_THRES=0.2, IOU_THRES=0.2\n"
     ]
    }
   ],
   "source": [
    "# נתיב למודל\n",
    "ONNX_PATH = \"/home/pi/Yahboom_project/uveye/code/raspberry-plate-recognition/yolov8n-license_plate.onnx\"\n",
    "\n",
    "# פרמטרי זיהוי\n",
    "CONF_THRES = 0.2      # סף ביטחון - נמוך = מזהה יותר אבל יותר טעויות\n",
    "IOU_THRES = 0.2       # טיפול בזיהויים חופפים\n",
    "INFER_PERIOD_S = 0.03 # תדירות הרצת AI (33 פעמים בשנייה)\n",
    "\n",
    "# טעינת המודל\n",
    "onnxr.set_default_logger_severity(3)  # השתקת הודעות מיותרות\n",
    "session = onnxr.InferenceSession(ONNX_PATH, providers=[\"CPUExecutionProvider\"])\n",
    "\n",
    "# בדיקת קלט המודל\n",
    "inp = session.get_inputs()[0]\n",
    "print(f\"✅ מודל YOLO נטען!\")\n",
    "print(f\"📊 קלט: {inp.name}, צורה: {inp.shape}\")\n",
    "print(f\"⚙️ CONF_THRES={CONF_THRES}, IOU_THRES={IOU_THRES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f0f31f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 🔍 שלב 3: זיהוי לוחית פשוט (ללא OCR)\n",
    "\n",
    "נתחיל רק עם הזיהוי - נראה איפה המודל מוצא לוחיות.\n",
    "\n",
    "**איך זה עובד:**\n",
    "1. קריאת תמונה מהמצלמה\n",
    "2. שליחת התמונה למודל YOLO\n",
    "3. המודל מחזיר: \"מצאתי לוחית ב-X, Y עם רוחב W וגובה H\"\n",
    "4. נצייר ריבוע ירוק סביב הלוחית\n",
    "\n",
    "**טיפ:** נסו עם תמונת לוחית על מסך הטלפון או הדפסה."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da97054f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Checking for processes using /dev/video0...\n",
      "[INFO] /dev/video0 is free.\n",
      "🔍 מזהה לוחיות (ללא OCR)...\n",
      "הראו לוחית רכב (אפשר על מסך/נייר)\n",
      "עצרו ע\"י Interrupt של התא (Kernel -> Interrupt)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aea25588be964d5487603ef5b21a3156",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ סיימתי\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 56\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# הרצת AI רק כל INFER_PERIOD_S (לחסוך CPU)\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m now \u001b[38;5;241m-\u001b[39m last_infer \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m INFER_PERIOD_S:\n\u001b[0;32m---> 56\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mrun_onnx_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m     detections \u001b[38;5;241m=\u001b[39m decode_yolov8(\n\u001b[1;32m     58\u001b[0m         output, frame\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], frame\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m     59\u001b[0m         CONF_THRES, IOU_THRES\n\u001b[1;32m     60\u001b[0m     )\n\u001b[1;32m     61\u001b[0m     last_infer \u001b[38;5;241m=\u001b[39m now\n",
      "File \u001b[0;32m~/Yahboom_project/uveye/code/raspberry-plate-recognition/helper_function.py:179\u001b[0m, in \u001b[0;36mrun_onnx_inference\u001b[0;34m(frame_bgr)\u001b[0m\n\u001b[1;32m    177\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtranspose(x, (\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))          \u001b[38;5;66;03m# HWC -> CHW\u001b[39;00m\n\u001b[1;32m    178\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(x, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)           \u001b[38;5;66;03m# -> NCHW\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:287\u001b[0m, in \u001b[0;36mSession.run\u001b[0;34m(self, output_names, input_feed, run_options)\u001b[0m\n\u001b[1;32m    285\u001b[0m     output_names \u001b[38;5;241m=\u001b[39m [output\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs_meta]\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_feed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m C\u001b[38;5;241m.\u001b[39mEPFail \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_fallback:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# שחרור מצלמה אם תקועה\n",
    "free_camera()\n",
    "\n",
    "import cv2\n",
    "import time\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "print(\"🔍 מזהה לוחיות (ללא OCR)...\")\n",
    "print(\"הראו לוחית רכב (אפשר על מסך/נייר)\")\n",
    "print(\"עצרו ע\\\"י Interrupt של התא (Kernel -> Interrupt)\\n\")\n",
    "\n",
    "# --- camera open (use V4L2 on Raspberry Pi if needed) ---\n",
    "cap = cv2.VideoCapture(0)  # try: cv2.VideoCapture(0, cv2.CAP_V4L2)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)  # may be ignored, but helps when supported\n",
    "\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(\"Cannot open camera\")\n",
    "\n",
    "# warm-up + drop stale frames\n",
    "for _ in range(20):\n",
    "    cap.read()\n",
    "\n",
    "# --- widget output ---\n",
    "img = widgets.Image(format=\"jpeg\")\n",
    "display(img)\n",
    "\n",
    "# --- streaming loop parameters ---\n",
    "TARGET_FPS = 20\n",
    "JPEG_QUALITY = 75\n",
    "DROP_GRABS = 2\n",
    "DT = 1.0 / TARGET_FPS\n",
    "\n",
    "last_infer = 0.0\n",
    "detections = []\n",
    "\n",
    "try:\n",
    "    t_next = time.time()\n",
    "    while True:\n",
    "        # drop a couple frames so we always show the newest\n",
    "        for _ in range(DROP_GRABS):\n",
    "            cap.grab()\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"failed read\")\n",
    "            time.sleep(0.05)\n",
    "            continue\n",
    "\n",
    "        now = time.time()\n",
    "\n",
    "        # הרצת AI רק כל INFER_PERIOD_S (לחסוך CPU)\n",
    "        if now - last_infer >= INFER_PERIOD_S:\n",
    "            output = run_onnx_inference(frame)\n",
    "            detections = decode_yolov8(\n",
    "                output, frame.shape[1], frame.shape[0],\n",
    "                CONF_THRES, IOU_THRES\n",
    "            )\n",
    "            last_infer = now\n",
    "\n",
    "        vis = frame.copy()\n",
    "\n",
    "        # ציור כל הלוחיות שנמצאו\n",
    "        for det in detections:\n",
    "            x1, y1, x2, y2 = det[\"bbox\"]\n",
    "            conf = det[\"confidence\"]\n",
    "\n",
    "            cv2.rectangle(vis, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(vis, f\"{conf:.2f}\", (x1, y1-5),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "        # מונה\n",
    "        cv2.putText(vis, f\"Plates: {len(detections)}\", (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 255), 2)\n",
    "\n",
    "        # encode BGR -> JPEG (fast + smooth in notebooks)\n",
    "        ok, jpg = cv2.imencode(\".jpg\", vis, [int(cv2.IMWRITE_JPEG_QUALITY), JPEG_QUALITY])\n",
    "        if ok:\n",
    "            img.value = jpg.tobytes()\n",
    "\n",
    "        # pace output (prevents flicker + CPU spikes)\n",
    "        sleep = t_next - time.time()\n",
    "        if sleep > 0:\n",
    "            time.sleep(sleep)\n",
    "        t_next = max(t_next + DT, time.time())\n",
    "\n",
    "finally:\n",
    "    cap.release()\n",
    "    print(\"✅ סיימתי\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a880d6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 🔤 שלב 4: הוספת OCR - קריאת המספרים\n",
    "\n",
    "עכשיו נוסיף את השלב השני: קריאת הטקסט מהלוחית.\n",
    "\n",
    "### תהליך עיבוד התמונה (לשיפור הקריאה):\n",
    "\n",
    "1. **גזירה (crop)** - חותכים רק את הלוחית + שוליים\n",
    "2. **המרה לשחור-לבן (grayscale)**\n",
    "3. **CLAHE** - שיפור ניגודיות (כמו \"בהירות אוטומטית\")\n",
    "4. **הגדלה (resize)** - x2.4 - OCR עובד טוב יותר על תמונות גדולות\n",
    "5. **טשטוש קל (blur)** - מסיר רעש\n",
    "6. **סף (threshold)** - שחור-לבן חד (ללא אפור)\n",
    "7. **OCR** - פעמיים: על הרגיל ועל ההפוך (שחור↔לבן)\n",
    "\n",
    "### פורמט לוחית ישראלית:\n",
    "- 7 ספרות: `12-345-67`\n",
    "- 8 ספרות: `123-45-678`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "073a391c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ פונקציות OCR מוכנות!\n",
      "📋 פורמטים: XX-XXX-XX (7) או XXX-XX-XXX (8)\n"
     ]
    }
   ],
   "source": [
    "# הגדרות OCR\n",
    "OCR_EVERY_N_FRAMES = 3  # OCR רק כל 3 פריימים (חוסך זמן)\n",
    "MARGIN_X = 0.10         # שוליים אופקיים (10%)\n",
    "MARGIN_Y = 0.25         # שוליים אנכיים (25%)\n",
    "\n",
    "# CLAHE - לשיפור ניגודיות\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "\n",
    "def normalize_plate(raw_text):\n",
    "    \"\"\"ממיר OCR גולמי לפורמט לוחית\"\"\"\n",
    "    # הסרת כל מה שלא ספרה\n",
    "    digits = re.sub(r\"\\D\", \"\", raw_text or \"\")\n",
    "    \n",
    "    if len(digits) == 7:\n",
    "        return f\"{digits[:2]}-{digits[2:5]}-{digits[5:]}\"\n",
    "    elif len(digits) == 8:\n",
    "        return f\"{digits[:3]}-{digits[3:5]}-{digits[5:]}\"\n",
    "    return None\n",
    "\n",
    "def crop_plate(frame, bbox):\n",
    "    \"\"\"גוזר את הלוחית עם שוליים\"\"\"\n",
    "    x1, y1, x2, y2 = bbox\n",
    "    w, h = x2 - x1, y2 - y1\n",
    "    mx = int(w * MARGIN_X)\n",
    "    my = int(h * MARGIN_Y)\n",
    "    \n",
    "    return frame[\n",
    "        max(0, y1 - my):min(frame.shape[0], y2 + my),\n",
    "        max(0, x1 - mx):min(frame.shape[1], x2 + mx)\n",
    "    ]\n",
    "\n",
    "def ocr_plate(crop_img):\n",
    "    \"\"\"מבצע OCR על תמונת לוחית\"\"\"\n",
    "    if crop_img is None or crop_img.size == 0:\n",
    "        return None\n",
    "    \n",
    "    # עיבוד\n",
    "    gray = cv2.cvtColor(crop_img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = clahe.apply(gray)\n",
    "    gray = cv2.resize(gray, None, fx=2.4, fy=2.4, interpolation=cv2.INTER_CUBIC)\n",
    "    gray = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "    \n",
    "    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # ניסיון OCR על שתי גרסאות (רגיל + הפוך)\n",
    "    for img in (binary, 255 - binary):\n",
    "        text = pytesseract.image_to_string(img, config=CONFIG_TESS)\n",
    "        plate = normalize_plate(text)\n",
    "        if plate:\n",
    "            return plate\n",
    "    \n",
    "    return None\n",
    "\n",
    "print(\"✅ פונקציות OCR מוכנות!\")\n",
    "print(f\"📋 פורמטים: XX-XXX-XX (7) או XXX-XX-XXX (8)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68502447",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 🎯 שלב 5: זיהוי + קריאה מלאה\n",
    "\n",
    "עכשיו נשלב הכל: זיהוי + OCR.\n",
    "\n",
    "**מה יוצג:**\n",
    "- ריבוע ירוק סביב הלוחית\n",
    "- הטקסט שנקרא (או \"----\" אם לא הצליח)\n",
    "- צבע ירוק אם הצליח לקרוא פורמט חוקי"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fe71a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Checking for processes using /dev/video0...\n",
      "[INFO] /dev/video0 is free.\n",
      "🔍 זיהוי + קריאה מלאה\n",
      "הראו לוחית רכב - המערכת תקרא את המספר\n",
      "עצרו ע\"י Interrupt של התא (Kernel -> Interrupt)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd0bcbeb89c04e81b5dd9acdce194ff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 קראתי: 911-79-181\n",
      "📋 קראתי: 911-79-181\n",
      "📋 קראתי: 91-179-48\n",
      "✅ סיימתי\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 60\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# זיהוי\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m now \u001b[38;5;241m-\u001b[39m last_infer \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m INFER_PERIOD_S:\n\u001b[0;32m---> 60\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mrun_onnx_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m     detections \u001b[38;5;241m=\u001b[39m decode_yolov8(\n\u001b[1;32m     62\u001b[0m         output, frame\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], frame\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m     63\u001b[0m         CONF_THRES, IOU_THRES\n\u001b[1;32m     64\u001b[0m     )\n\u001b[1;32m     65\u001b[0m     last_infer \u001b[38;5;241m=\u001b[39m now\n",
      "File \u001b[0;32m~/Yahboom_project/uveye/code/raspberry-plate-recognition/helper_function.py:179\u001b[0m, in \u001b[0;36mrun_onnx_inference\u001b[0;34m(frame_bgr)\u001b[0m\n\u001b[1;32m    177\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtranspose(x, (\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))          \u001b[38;5;66;03m# HWC -> CHW\u001b[39;00m\n\u001b[1;32m    178\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(x, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)           \u001b[38;5;66;03m# -> NCHW\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:287\u001b[0m, in \u001b[0;36mSession.run\u001b[0;34m(self, output_names, input_feed, run_options)\u001b[0m\n\u001b[1;32m    285\u001b[0m     output_names \u001b[38;5;241m=\u001b[39m [output\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs_meta]\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_feed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m C\u001b[38;5;241m.\u001b[39mEPFail \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_fallback:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "free_camera()\n",
    "\n",
    "import cv2\n",
    "import time\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "print(\"🔍 זיהוי + קריאה מלאה\")\n",
    "print(\"הראו לוחית רכב - המערכת תקרא את המספר\")\n",
    "print(\"עצרו ע\\\"י Interrupt של התא (Kernel -> Interrupt)\\n\")\n",
    "\n",
    "# --- Best-practice smooth live camera in Jupyter: ipywidgets.Image (no matplotlib redraw)\n",
    "# --- camera open (use V4L2 on Raspberry Pi if needed) ---\n",
    "cap = cv2.VideoCapture(0)  # try: cv2.VideoCapture(0, cv2.CAP_V4L2)\n",
    "\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)  # may be ignored, but helps when supported\n",
    "\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(\"Cannot open camera\")\n",
    "\n",
    "# warm-up + drop stale frames\n",
    "for _ in range(20):\n",
    "    cap.read()\n",
    "\n",
    "# --- widget output ---\n",
    "img = widgets.Image(format=\"jpeg\")\n",
    "display(img)\n",
    "\n",
    "# --- streaming loop parameters ---\n",
    "TARGET_FPS = 20\n",
    "JPEG_QUALITY = 75\n",
    "DROP_GRABS = 2\n",
    "DT = 1.0 / TARGET_FPS\n",
    "\n",
    "last_infer = 0.0\n",
    "detections = []\n",
    "frame_count = 0\n",
    "last_ocr_result = {}\n",
    "\n",
    "try:\n",
    "    t_next = time.time()\n",
    "    while True:\n",
    "        # drop a couple frames so we always show the newest\n",
    "        for _ in range(DROP_GRABS):\n",
    "            cap.grab()\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"failed read\")\n",
    "            time.sleep(0.05)\n",
    "            continue\n",
    "\n",
    "        now = time.time()\n",
    "        frame_count += 1\n",
    "\n",
    "        # זיהוי\n",
    "        if now - last_infer >= INFER_PERIOD_S:\n",
    "            output = run_onnx_inference(frame)\n",
    "            detections = decode_yolov8(\n",
    "                output, frame.shape[1], frame.shape[0],\n",
    "                CONF_THRES, IOU_THRES\n",
    "            )\n",
    "            last_infer = now\n",
    "\n",
    "        vis = frame.copy()\n",
    "\n",
    "        if detections:\n",
    "            # נעבוד על הלוחית הכי בטוחה\n",
    "            best = max(detections, key=lambda d: d[\"confidence\"])\n",
    "            x1, y1, x2, y2 = best[\"bbox\"]\n",
    "\n",
    "            cv2.rectangle(vis, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "            # OCR כל N פריימים\n",
    "            if frame_count % OCR_EVERY_N_FRAMES == 0:\n",
    "                crop = crop_plate(frame, (x1, y1, x2, y2))\n",
    "                plate_text = ocr_plate(crop)\n",
    "\n",
    "                if plate_text:\n",
    "                    last_ocr_result = {\n",
    "                        \"text\": plate_text,\n",
    "                        \"time\": now,\n",
    "                        \"bbox\": (x1, y1, x2, y2)\n",
    "                    }\n",
    "                    print(f\"📋 קראתי: {plate_text}\")\n",
    "\n",
    "            # הצגת תוצאה אחרונה (אם קיימת ועדכנית)\n",
    "            if last_ocr_result and (now - last_ocr_result.get(\"time\", 0)) < 2.0:\n",
    "                txt = last_ocr_result[\"text\"]\n",
    "                cv2.putText(vis, f\"Plate: {txt}\", (10, 40),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 0), 3)\n",
    "            else:\n",
    "                cv2.putText(vis, \"OCR: ----\", (10, 40),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 3)\n",
    "\n",
    "        # show in notebook\n",
    "        ok, jpg = cv2.imencode(\".jpg\", vis, [int(cv2.IMWRITE_JPEG_QUALITY), JPEG_QUALITY])\n",
    "        if ok:\n",
    "            img.value = jpg.tobytes()\n",
    "\n",
    "        # pace output\n",
    "        sleep = t_next - time.time()\n",
    "        if sleep > 0:\n",
    "            time.sleep(sleep)\n",
    "        now2 = time.time()\n",
    "        t_next = max(t_next + DT, now2)\n",
    "\n",
    "finally:\n",
    "    cap.release()\n",
    "    print(\"✅ סיימתי\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87b0b4b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 🎯 שלב 6: חיפוש לוחית ספציפית\n",
    "\n",
    "עכשיו נוסיף \"משימה\": למצוא לוחית מסוימת!\n",
    "\n",
    "**איך זה עובד:**\n",
    "1. הגדרנו לוחית מטרה: `TARGET_PLATE = \"91-179-18\"`\n",
    "2. המערכת מזהה + קוראת לוחיות\n",
    "3. כשמוצאת את המטרה → **LOCK!** (לא מחפשת יותר)\n",
    "4. הצגה ירוקה + הודעה\n",
    "\n",
    "**שימוש:** משחק \"מצא את הרכב\" או בקרת כניסה לחניון."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "886aed09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Checking for processes using /dev/video0...\n",
      "[INFO] /dev/video0 is free.\n",
      "🎯 מחפש לוחית: 91-179-18\n",
      "הראו לוחיות שונות עד שתמצא את המטרה\n",
      "עצרו ע\"י Interrupt של התא (Kernel -> Interrupt)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3699587a848f4a8d9022f4a9ea1119b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 קראתי: 191-17-918\n",
      "📋 קראתי: 19-179-18\n",
      "📋 קראתי: 191-17-918\n",
      "📋 קראתי: 191-17-918\n",
      "📋 קראתי: 19-179-81\n",
      "📋 קראתי: 19-179-18\n",
      "📋 קראתי: 19-179-81\n",
      "📋 קראתי: 191-17-918\n",
      "📋 קראתי: 91-179-18\n",
      "\n",
      "🎉🎉🎉 מצאתי את המטרה: 91-179-18 🎉🎉🎉\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 54\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(DROP_GRABS):\n\u001b[1;32m     52\u001b[0m     cap\u001b[38;5;241m.\u001b[39mgrab()\n\u001b[0;32m---> 54\u001b[0m ret, frame \u001b[38;5;241m=\u001b[39m \u001b[43mcap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ret:\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfailed read\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# לוחית מטרה (שנו לפי הצורך!)\n",
    "TARGET_PLATE = \"91-179-18\"\n",
    "\n",
    "free_camera()\n",
    "\n",
    "import cv2\n",
    "import time\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "print(f\"🎯 מחפש לוחית: {TARGET_PLATE}\")\n",
    "print(\"הראו לוחיות שונות עד שתמצא את המטרה\")\n",
    "print(\"עצרו ע\\\"י Interrupt של התא (Kernel -> Interrupt)\\n\")\n",
    "\n",
    "# --- Best-practice smooth live camera in Jupyter: ipywidgets.Image (no matplotlib redraw)\n",
    "# --- camera open (use V4L2 on Raspberry Pi if needed) ---\n",
    "cap = cv2.VideoCapture(0)  # try: cv2.VideoCapture(0, cv2.CAP_V4L2)\n",
    "\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)  # may be ignored, but helps when supported\n",
    "\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(\"Cannot open camera\")\n",
    "\n",
    "# warm-up + drop stale frames\n",
    "for _ in range(20):\n",
    "    cap.read()\n",
    "\n",
    "# --- widget output ---\n",
    "img = widgets.Image(format=\"jpeg\")\n",
    "display(img)\n",
    "\n",
    "# --- streaming loop parameters ---\n",
    "TARGET_FPS = 20\n",
    "JPEG_QUALITY = 75\n",
    "DROP_GRABS = 2\n",
    "DT = 1.0 / TARGET_FPS\n",
    "\n",
    "last_infer = 0.0\n",
    "detections = []\n",
    "frame_count = 0\n",
    "target_found = False\n",
    "target_data = None\n",
    "last_guess = None\n",
    "\n",
    "try:\n",
    "    t_next = time.time()\n",
    "    while True:\n",
    "        # drop a couple frames so we always show the newest\n",
    "        for _ in range(DROP_GRABS):\n",
    "            cap.grab()\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"failed read\")\n",
    "            time.sleep(0.05)\n",
    "            continue\n",
    "\n",
    "        now = time.time()\n",
    "        frame_count += 1\n",
    "\n",
    "        # זיהוי\n",
    "        if now - last_infer >= INFER_PERIOD_S:\n",
    "            output = run_onnx_inference(frame)\n",
    "            detections = decode_yolov8(\n",
    "                output, frame.shape[1], frame.shape[0],\n",
    "                CONF_THRES, IOU_THRES\n",
    "            )\n",
    "            last_infer = now\n",
    "\n",
    "        vis = frame.copy()\n",
    "\n",
    "        if detections:\n",
    "            best = max(detections, key=lambda d: d[\"confidence\"])\n",
    "            x1, y1, x2, y2 = best[\"bbox\"]\n",
    "\n",
    "            # OCR רק אם עדיין לא מצאנו\n",
    "            if not target_found and frame_count % OCR_EVERY_N_FRAMES == 0:\n",
    "                crop = crop_plate(frame, (x1, y1, x2, y2))\n",
    "                plate_text = ocr_plate(crop)\n",
    "\n",
    "                if plate_text:\n",
    "                    last_guess = plate_text\n",
    "                    print(f\"📋 קראתי: {plate_text}\")\n",
    "\n",
    "                    # בדיקה מול מטרה\n",
    "                    if plate_text == TARGET_PLATE:\n",
    "                        target_found = True\n",
    "                        target_data = {\n",
    "                            \"text\": plate_text,\n",
    "                            \"bbox\": (x1, y1, x2, y2),\n",
    "                            \"time\": now\n",
    "                        }\n",
    "                        print(f\"\\n🎉🎉🎉 מצאתי את המטרה: {TARGET_PLATE} 🎉🎉🎉\\n\")\n",
    "\n",
    "            # ציור\n",
    "            color = (0, 255, 0) if target_found else (255, 255, 0)\n",
    "            cv2.rectangle(vis, (x1, y1), (x2, y2), color, 3 if target_found else 2)\n",
    "\n",
    "        # תצוגה\n",
    "        if target_found:\n",
    "            cv2.putText(vis, f\"TARGET: {TARGET_PLATE}\", (10, 40),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 3)\n",
    "            cv2.putText(vis, \"*** FOUND ***\", (10, 80),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 0), 3)\n",
    "        else:\n",
    "            cv2.putText(vis, f\"Looking for: {TARGET_PLATE}\", (10, 30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "            if last_guess:\n",
    "                cv2.putText(vis, f\"Last: {last_guess}\", (10, 60),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)\n",
    "\n",
    "        # show in notebook\n",
    "        ok, jpg = cv2.imencode(\".jpg\", vis, [int(cv2.IMWRITE_JPEG_QUALITY), JPEG_QUALITY])\n",
    "        if ok:\n",
    "            img.value = jpg.tobytes()\n",
    "\n",
    "        # pace output\n",
    "        sleep = t_next - time.time()\n",
    "        if sleep > 0:\n",
    "            time.sleep(sleep)\n",
    "        now2 = time.time()\n",
    "        t_next = max(t_next + DT, now2)\n",
    "\n",
    "finally:\n",
    "    cap.release()\n",
    "\n",
    "if target_found:\n",
    "    print(f\"✅ סיימתי - מצאתי את {TARGET_PLATE}!\")\n",
    "else:\n",
    "    print(\"⚠️ סיימתי - לא מצאתי את המטרה\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145e5e38",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 📊 סיכום - מושגים ופרמטרים\n",
    "\n",
    "### מושגים:\n",
    "\n",
    "| מושג | הסבר |\n",
    "|------|------|\n",
    "| **YOLO** | מודל AI לזיהוי אובייקטים (כאן: לוחיות) |\n",
    "| **ONNX** | פורמט למודלי AI שעובד על מכשירים חלשים |\n",
    "| **OCR** | Optical Character Recognition - קריאת טקסט |\n",
    "| **Tesseract** | תוכנת OCR בקוד פתוח |\n",
    "| **CLAHE** | שיפור ניגודיות אדפטיבי |\n",
    "| **Threshold** | המרה לשחור-לבן חד |\n",
    "| **Confidence** | רמת ביטחון של ה-AI (0.0-1.0) |\n",
    "| **IOU** | Intersection Over Union - למניעת זיהויים כפולים |\n",
    "\n",
    "### פרמטרים לכיוונון:\n",
    "\n",
    "| פרמטר | טווח | ברירת מחדל | השפעה |\n",
    "|--------|------|------------|--------|\n",
    "| `CONF_THRES` | 0.1-0.8 | 0.2 | סף זיהוי - נמוך=יותר זיהויים (ויותר טעויות) |\n",
    "| `IOU_THRES` | 0.1-0.5 | 0.2 | מניעת כפילויות |\n",
    "| `INFER_PERIOD_S` | 0.03-0.2 | 0.03 | תדירות AI - נמוך=מדויק אבל איטי |\n",
    "| `OCR_EVERY_N_FRAMES` | 1-10 | 3 | כל כמה פריימים OCR - גבוה=מהיר אבל פחות רספונסיבי |\n",
    "| `MARGIN_X/Y` | 0.0-0.3 | 0.1/0.25 | שוליים לגזירה - גדול=יותר הקשר |\n",
    "\n",
    "### שרשרת עיבוד:\n",
    "\n",
    "```\n",
    "תמונה מקורית\n",
    "    ↓\n",
    "YOLO (זיהוי bbox)\n",
    "    ↓\n",
    "Crop + Margins (גזירה)\n",
    "    ↓\n",
    "Grayscale (שחור-לבן)\n",
    "    ↓\n",
    "CLAHE (שיפור ניגודיות)\n",
    "    ↓\n",
    "Resize x2.4 (הגדלה)\n",
    "    ↓\n",
    "Blur (טשטוש קל)\n",
    "    ↓\n",
    "Threshold (סף)\n",
    "    ↓\n",
    "Tesseract OCR\n",
    "    ↓\n",
    "Normalize (פורמט)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 💡 רעיונות לשיפורים\n",
    "\n",
    "1. **מסד נתונים:**\n",
    "   - שמרו כל לוחית שנקראה עם timestamp\n",
    "   - בסוף: \"ראיתי 5 לוחיות שונות\"\n",
    "\n",
    "2. **סטטיסטיקות:**\n",
    "   - כמה זיהויים? כמה מהם הצליחו OCR?\n",
    "   - אחוז הצלחה\n",
    "\n",
    "3. **משחק \"זיכרון\":**\n",
    "   - הראו 3 לוחיות\n",
    "   - המערכת תזכור אותן\n",
    "   - הראו שוב - האם זוכרת?\n",
    "\n",
    "4. **בקרת כניסה:**\n",
    "   - רשימת לוחיות מורשות\n",
    "   - אם נמצאה → \"כניסה מאושרת\"\n",
    "   - אחרת → \"כניסה נדחתה\"\n",
    "\n",
    "**בהצלחה! 🚗🔍**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
